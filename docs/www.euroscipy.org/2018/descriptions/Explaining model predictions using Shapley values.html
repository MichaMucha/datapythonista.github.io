<!DOCTYPE html>
<head>
    <meta charset="utf-8" />
    <!-- Set the viewport width to device width for mobile -->
    <meta name="viewport" content="width=device-width" />

    <title>Explaining model predictions using Shapley values</title>

    <link rel="stylesheet" href="../../theme/css/normalize.css" />
    <link rel="stylesheet" href="../../theme/css/foundation.min.css" />
    <link rel="stylesheet" href="../../theme/css/style.css" />
    <link rel="stylesheet" href="../../theme/css/pygments.css" />	
    <link rel="shortcut icon" href="../../theme/images/icons/favicon.ico"/>
    <script src="../../theme/js/custom.modernizr.js"></script>
    <link rel="stylesheet" href="../../static/2019/euroscipy.css" />
</head>

<body>

<!-- Nav Bar -->
<nav>
<div class="top-bar">
<div class="row">
    <div class="large-9 large-centered columns">
      <a href="../.."><img src="../../theme/images/euroscipy_logo.png" alt="EuroSciPy Website"/></a>
      <h1>EuroSciPy</h1>
    </div>
</div>
</div>

<!-- Show menu items and pages -->
<div class="row">
<div class="large-9 columns">
    <ul class="button-group navigation">

    </ul>
</div>
</div>
</nav>
<!-- End Nav -->


<!-- Main Page Content and Sidebar -->
<div class="row">

    <!-- Main Blog Content -->
    <div class="large-9 columns">
        
    <h3>Explaining model predictions using Shapley values</h3>
    
    <h1>Explaining model predictions using Shapley values</h1>
<p>Finding the contribution of each of our features towards predictions could have a lot of interesting applications. We can use it to reduce the dimensionality of our problem to deal with the curse of dimensionality. We can also use it for finding correlated features in our dataset. It can also be used in clustering applications[1].</p>
<p>The concept of Shapley values comes from cooperative game theory. Shapley value tries to find how important is each player in the overall cooperation, and what payoff can the player expect for the cooperation. This concept can be transferred to machine learning by assuming each feature as a player and the learning task to be a cooperative game[2]. </p>
<p>Python has a great tool for working with Shapley values called shap (https://github.com/slundberg/shap). Shap[3] provides a unified framework for explaining the outputs of any kind of machine learning models.</p>
<p>This talk will focus on the following points:
1. Why we are interested in explaining our predictions
2. Introduction to Shapley values using Game Theory
3. Application of Shapley values in data science
4. Examples using shap (https://github.com/slundberg/shap)
5. Comparison with other similar methods.</p>
<p><strong>References:</strong>
[1] Dhamal, Swapnil, et al. "Pattern clustering using cooperative game theory." arXiv preprint arXiv:1201.0461 (2012).
[2] Lundberg, Scott M., and Su-In Lee. "A unified approach to interpreting model predictions." Advances in Neural Information Processing Systems. 2017.
[3] https://github.com/slundberg/shap</p>
    </div>
    <!-- End Main Content -->

</div> <!-- End Main Content and Sidebar -->


<footer role="contentinfo"><!-- Footer -->
<footer class="row">
    <div class="large-12 columns">
        <hr />
        <div class="row">
            <div class="large-8 columns">
                <p>EuroSciPy by The EuroSciPy team <info@euroscipy.org></p>
            </div>
            <div class="large-4 columns">
            	<a href="privacy.html"> Privacy terms</a>
            </div>
    </div>
</footer></footer>