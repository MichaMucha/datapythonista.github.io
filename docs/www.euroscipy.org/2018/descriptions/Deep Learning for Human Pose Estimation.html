<!DOCTYPE html>
<head>
    <meta charset="utf-8" />
    <!-- Set the viewport width to device width for mobile -->
    <meta name="viewport" content="width=device-width" />

    <title>Deep Learning for Human Pose Estimation</title>

    <link rel="stylesheet" href="../../theme/css/normalize.css" />
    <link rel="stylesheet" href="../../theme/css/foundation.min.css" />
    <link rel="stylesheet" href="../../theme/css/style.css" />
    <link rel="stylesheet" href="../../theme/css/pygments.css" />	
    <link rel="shortcut icon" href="../../theme/images/icons/favicon.ico"/>
    <script src="../../theme/js/custom.modernizr.js"></script>
    <link rel="stylesheet" href="../../static/2019/euroscipy.css" />
</head>

<body>

<!-- Nav Bar -->
<nav>
<div class="top-bar">
<div class="row">
    <div class="large-9 large-centered columns">
      <a href="../.."><img src="../../theme/images/euroscipy_logo.png" alt="EuroSciPy Website"/></a>
      <h1>EuroSciPy</h1>
    </div>
</div>
</div>

<!-- Show menu items and pages -->
<div class="row">
<div class="large-9 columns">
    <ul class="button-group navigation">

    </ul>
</div>
</div>
</nav>
<!-- End Nav -->


<!-- Main Page Content and Sidebar -->
<div class="row">

    <!-- Main Blog Content -->
    <div class="large-9 columns">
        
    <h3>Deep Learning for Human Pose Estimation</h3>
    
    <h1>Deep Learning for Human Pose Estimation</h1>
<p>Robots are coming. Whether they come as humanoids, home assistants or self-driving cars, but they're coming. They're coming out from the orderly, synthetic and isolated manufacturing plants to the chaotic, evolutionary and interactive real world. And it's this interaction what will separate these machines between lifeless appliance and sociable robots. Understanding both verbal and non-verbal communication is the last layer of robotic development, though it may be one of the more challengings.</p>
<p>Fortunately, deep learning emerged a few years ago with astonishing results. It has led to huge advances in verbal human-machine communication and it's starting to see great outcomes in non-verbal. Detecting the 3D position and orientation of the people around you with no more than an RGB camera is increasingly becoming a reality.</p>
<p>Throughout the talk, we'll cover the process from receiving an RGB image to make a real robot detect a person position and orientation to finally approach her. And everything with Python.
<em> The magic: design of the neural network architecture (OpenPose) to detect body keypoints (such as eyes, neck, shoulders or knees), discussing methods to make it faster though losing accuracy.
</em> Postprocessing: If there are a bunch of people, which part belongs to which person? 
<em> From 2D to 3D: heuristics to extract position and orientation of a human from its skeleton.
</em> Application: integration of the model into a real assistant robot, using the position and orientation information to approach the person face-to-face.</p>
    </div>
    <!-- End Main Content -->

</div> <!-- End Main Content and Sidebar -->


<footer role="contentinfo"><!-- Footer -->
<footer class="row">
    <div class="large-12 columns">
        <hr />
        <div class="row">
            <div class="large-8 columns">
                <p>EuroSciPy by The EuroSciPy team <info@euroscipy.org></p>
            </div>
            <div class="large-4 columns">
            	<a href="privacy.html"> Privacy terms</a>
            </div>
    </div>
</footer></footer>