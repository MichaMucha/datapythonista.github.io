<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>pandas: The two cultures</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
  <link href="https://datapythonista.github.io/blog/" rel="canonical" />

  <!-- Feed -->
        <link href="https://datapythonista.github.io/blog/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="datapythonista blog Full Atom Feed" />

  <link href="https://datapythonista.github.io/blog/theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="https://datapythonista.github.io/blog/theme/css/code_blocks/github.css" rel="stylesheet">

    <!-- CSS specified by the user -->


    <link href="https://datapythonista.github.io/blog/../static/css/blog.css" type="text/css" rel="stylesheet" />

  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->


  <link href="https://datapythonista.github.io/blog/pandas-the-two-cultures.html" rel="canonical" />

    <meta name="description" content="Leo Breiman was a distinguished statistician at UC Berkeley, known among other things for his major contributions to CART (decision...">

    <meta name="author" content="Marc">

    <meta name="tags" content="pandas">




<!-- Open Graph -->
<meta property="og:site_name" content="datapythonista blog"/>
<meta property="og:title" content="pandas: The two cultures"/>
<meta property="og:description" content="Leo Breiman was a distinguished statistician at UC Berkeley, known among other things for his major contributions to CART (decision..."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://datapythonista.github.io/blog/pandas-the-two-cultures.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2019-07-22 23:26:00+01:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://datapythonista.github.io/blog/author/marc.html">
<meta property="article:section" content="misc"/>
<meta property="article:tag" content="pandas"/>
<meta property="og:image" content="https://datapythonista.github.io/blog/../static/img/bg.jpg">

<!-- Twitter Card -->

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "name": "pandas: The two cultures",
  "headline": "pandas: The two cultures",
  "datePublished": "2019-07-22 23:26:00+01:00",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": "Marc",
    "url": "https://datapythonista.github.io/blog/author/marc.html"
  },
  "image": "https://datapythonista.github.io/blog/../static/img/bg.jpg",
  "url": "https://datapythonista.github.io/blog/pandas-the-two-cultures.html",
  "description": "Leo Breiman was a distinguished statistician at UC Berkeley, known among other things for his major contributions to CART (decision..."
}
</script>
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>


    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" class="has-cover">
      <div class="inner">
        <nav id="navigation">
            <span class="blog-logo">
                <a href="https://datapythonista.github.io/blog/"><img src="../static/img/profile.png" alt="Blog Logo" /></a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">pandas: The two cultures</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="https://datapythonista.github.io/blog/author/marc.html">Marc</a>
            | <time datetime="Mon 22 July 2019">Mon 22 July 2019</time>
        </span>
        <!-- TODO : Modified check -->
            <div class="post-cover cover" style="background-image: url('https://datapythonista.github.io/blog/../static/img/bg.jpg')">
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <p><img alt="" src="/static/img/blog/two_cultures/leo_breiman.jpeg"></p>
<p><a href="https://www.stat.berkeley.edu/~breiman/">Leo Breiman</a> was a distinguished statistician at
UC Berkeley, known among other things for his major contributions to CART (decision trees),
and ensemble techniques, mainly bootstrap aggregation. Combining both, he was able to define
one of the most popular machine learning models even today (18 years after the publication
of the paper), <a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">Random forests</a>.</p>
<p>In 2001, Breiman published the paper
<a href="http://www2.math.uu.se/~thulin/mm/breiman.pdf">Statistical Modeling: The Two Cultures</a>.
In it, Breiman identified that there were two somehow conflicting cultures in the discipline
of statistical modeling. One that was focusing on modeling (and trying to understand) the
stochastic process generating some random data. While the other followed an algorithmic
approach focused on obtaining results (minimizing the error between the model results and
the data), and considered the stochastic process a black box. Today we would probably call
them <em>statistics</em> and <em>machine learning</em>, and the division between them is clear. And in a way,
machine learning is not even considered part of statistics. While this division among the two
fields may or may not be a good thing, identifying in 2001 that both communities existed, were
different and had different needs, surely helped overcome the frustration of both communities at
that time, and sped up their development. One example that illustrate the differences can be
seen on how in the area of neural networks, publishing research papers is mostly driven by 
the obtained results, more than by the theory behind the results. Ali Rahimi gave
<a href="https://www.youtube.com/watch?v=Qi1Yry33TQE">his view</a> on this when receiving the test-of-time
award at NeurIPS 2017.</p>
<p>But this post is not about machine learning, but about <a href="https://pandas.pydata.org/">pandas</a>.
And about the two cultures in the pandas community, that I personally don't think are often
well identified, causing frustration to some users, and making more complex taking decisions
regarding the API of the project.</p>
<h2>Dr Jekyll and Mr Hyde</h2>
<p><img alt="" src="/static/img/blog/two_cultures/dr_jekyll_mr_hyde.jpeg"></p>
<p>To describe the two cultures, let me talk about my own professional experience.
For the last years I've been mainly working as a data scientist. Since the developers of
<a href="https://scikit-learn.org/stable/">scikit-learn</a> are doing all the <em>fun</em> work in machine learning,
and implementing all the complex algorithms for the rest of us, I'll argue that my job (and the
job of many other data scientists, some will probably disagree) is to work on data analysis to
find out what needs to be done, and data engineering to make it work in production.</p>
<p>What I call <strong>data analysis</strong> is performed in a <a href="https://jupyter.org/">Jupyter notebook</a>,
where I analyze and visualize the data. I found out what is wrong with it, and I quickly
grow the cells of my <code>Untitled23.ipynb</code> hoping I'll never have to look back at my dirty code.
What I value the most is being able to write code fast, and focus in the problem I'm solving, and
not in the code. To the extend I alias every Python library I import with incomprehensible names
like <code>np</code>, <code>pd</code>, <code>plt</code>,... to make sure I save few microseconds compared to typing the actual
names. And I really appreciate the software making as many decisions as needed to save me from
having to spend the time on being explicit on what I want. Ok, this may be a bit exaggerated,
I don't really let my notebook names be untitled whatever, or use aliases, but I think you get the idea.</p>
<p>On the other hand, when working in <strong>data engineering</strong> I use vim, and I write all my code in
Python files in a clear directory structure. Every file and directory are carefully named so I can
easily find them later. Every function is well documented, and the best coding standards are applied.
All my code is version controlled with git, and code reviewed by my colleagues. I write every single
line of code knowing that I will have to revisit it many times, and I optimize for its simplicity and
its clarity.  The thing I'm more adverse to is <em>magic</em> happening, and any software making decisions
for me. I want to be in control, I want everything in my code to be deterministic, and I want
everything in my code to be explicit. Everything that Tim Peters wrote in
<a href="https://www.python.org/dev/peps/pep-0020/">PEP-20</a>, the Zen of Python, applies:</p>
<ul>
<li>Beautiful is better than ugly.</li>
<li>Explicit is better than implicit.</li>
<li>Simple is better than complex.</li>
<li>Readability counts.</li>
<li>Errors should never pass silently.</li>
<li>...</li>
</ul>
<h2>One pandas to rule them all</h2>
<p><img alt="" src="/static/img/blog/two_cultures/ring.jpeg"></p>
<p>What I find the most interesting part about <em>the two cultures</em> I just described, is that I use
pandas for both. I think pandas is the best tool for both use cases, and I won't admit I'm biased
here, since I'm a pandas maintainer because I use the software, and not the other way round.</p>
<p>But how is that possible? Both use cases are radically different. Is pandas designed in a way that
is able offer both kind of users the API and features they need? Is that always possible?</p>
<p>The next of this post will try to find an answer by analyzing some examples.</p>
<h2>Show me the code</h2>
<h3>Creating data from a Python dict</h3>
<p>Let's start with a single example, by manually creating some data:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">pandas</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="s1">&#39;unicorn&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;spider&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;penguin&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span>
<span class="n">unicorn</span>    <span class="mi">4</span>
<span class="n">spider</span>     <span class="mi">8</span>
<span class="n">penguin</span>    <span class="mi">2</span>
<span class="n">dtype</span><span class="p">:</span> <span class="n">int64</span>
</pre></div>


<p>I think we can agree that pandas is letting us create our data in the simplest possible way. There
could be other ways (and there are other ways that pandas supports), but creating a Series looks to
me as simple as it can be. That's what I want as a data analyst.</p>
<p>But as a data engineer, there are more things to consider. Imagine that my data, instead of having 3
samples, had 3 million. How much memory is pandas consuming to store in memory my data? And why?
For simplicity, let's consider only the values (and not the name of the animals):</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="mi">24</span>
</pre></div>


<p>The values in our Series are consuming 24 bytes. If we see again the representation of our Series,
we can see how the data type (aka dtype) is <code>int64</code>. Meaning that every value will consume 64
bits (8 bytes). 8 bytes per value, multiplied by 3 values (the number of legs for unicorn, spider
and penguin) totals 24 bytes. But why 64 bits? pandas decided for us that representation, which can
store numbers from around -9e18 to 9e18. But do we really expect animals to have a number of legs
with 18 digits? Or do we expect negative numbers of legs at all? Probably not. We know it, but
pandas doesn't. Because pandas doesn't know anything about our domain, or what is reasonable,
it's deciding for us a conservative representation for our data that won't cause us problems
(as opposed as one that saves some memory).</p>
<p>This is working well for us as data analysts, but not as data engineers writing production code.
In this case, the Series constructor has a parameter <code>dtype</code> that we can use to tell pandas to not
decide for us how to internally represent the data, but to tell it explicitly. This is the result:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">pandas</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="s1">&#39;unicorn&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;spider&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;penguin&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span>
<span class="o">...</span>                          <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span>
<span class="n">unicorn</span>    <span class="mi">4</span>
<span class="n">spider</span>     <span class="mi">8</span>
<span class="n">penguin</span>    <span class="mi">2</span>
<span class="n">dtype</span><span class="p">:</span> <span class="n">uint8</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="mi">3</span>
</pre></div>


<p>In this example, pandas provides a reasonable API for both kind of users. It doesn't force us to
specify the data type when we don't care. But we're able to when we do care. Whether we want to
optimize for our system resources (mainly memory) or our own time is up to us.</p>
<h3>How many legs do unicorns have?</h3>
<p><img alt="" src="/static/img/blog/two_cultures/unicorn.jpeg"></p>
<p>An important question we face is, how many legs do unicorns have? In the previous example, we specified
they have 4, but do unicorns really have 4 legs? Did anybody have ever seen a unicorn? Let's try to be
prudent and say that we don't know how many legs they have. By convention, when we have an unknown
or missing value, we represent it as <code>NaN</code> (Not a Number). Every number in a computer is represented
using binary numbers (e.g. <code>01001011</code>). <code>NaN</code> is represented internally as one specific sequence of
bits, reserved to have the meaning of <code>NaN</code>. There is a convention that <em>translates</em> how every binary
sequence corresponds to the number they represent. And this <em>translation</em> has some exceptions, including
one value that represents the floating point number <code>NaN</code>. If that sounds too complex, think that in
binary, <code>0000</code> can represent the number 0, <code>0001</code> the 1, <code>0010</code>: 2, <code>0011</code>: 3... and <code>1111</code>: 15.
And what microprocessors manufacturers decided is something like letting represent only from 0 to 14
(instead of from 0 to 15, that we could encode with 4 bits), and reserve the <code>1111</code> to mean <code>NaN</code>.
Things are in reality more complex, since <code>NaN</code> representations only exists for floating points numbers
(aka float), which are decimals. But that explanation should give an intuition.</p>
<p>So, back to the example, if we want to represent that we don't know how many legs unicorns have, we
can simply do:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;unicorn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;NaN&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span>
<span class="n">unicorn</span>    <span class="n">NaN</span>
<span class="n">spider</span>     <span class="mf">8.0</span>
<span class="n">penguin</span>    <span class="mf">2.0</span>
<span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</pre></div>


<p>Many things happened here. We can see, how besides the expected change of having <code>NaN</code> unicorn legs,
now we are back to consuming 64 bits. And not only that, but also the rest of values in the column now are
decimal (float) values. As I just explained, and can also be seen in the example on how <code>NaN</code> is created,
<code>NaN</code> is a float value. Modern computers don't have an integer representation for <code>NaN</code>, so for pandas
to do what we asked it to do, converting the column to float was the <em>only</em> option (not really the only,
but let's pretend for a second).</p>
<p>It feels a bit weird to see in the Series representation that a penguin has 2.0 legs. It's conceptually
wrong, and also misleading making us believe that animals can have a decimal number of legs. There are
also technical implications too, we are consuming 4 times more memory now. And also operations among
integers don't take the same time as operations among floats at the CPU level (note that while floats
are a more complex representation, modern CPU's are highly optimized for them, and operations can even be
faster for floats than for integers).</p>
<p>But there is something else, see this example:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">==</span> <span class="mf">0.3</span>
<span class="bp">False</span>
</pre></div>


<p>Floating point numbers are approximations. They are mapping an infinite set of numbers (let's say all
real numbers) to the finite set of possible representations with 64 bits (<code>2 ** 64</code>). In many
cases using this approximate values won't make a difference (the height of a person keeps being the
same if we change the 20th decimal). But, if for example a column contains an integer id that we use
to join two data sets, converting it to floating point can mean data loss or bugs. Since floating points
are just approximations, we may try to join by <code>20.0000000001 == 19.9999999999</code>, which won't match.
So, converting an integer column to its floating point representation can be dangerous, and probably
more for the data engineering use cases described before.</p>
<p>In pandas 0.24 we introduced a new data type to mix integer values with missing values. This is done
by instead of using the float <code>NaN</code> to represent the missing values, we internally keep a separate
Boolean array that identifies where the missing values are. This adds an extra layer of complexity
inside pandas, but avoids problems like the one just described. By default, pandas still uses the
original types, but we can write the previous code as follows:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="s1">&#39;unicorn&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;spider&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;penguin&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span>
<span class="o">...</span>                          <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;UInt8&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;unicorn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;NaN&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span>
<span class="n">unicorn</span>    <span class="n">NaN</span>
<span class="n">spider</span>       <span class="mi">8</span>
<span class="n">penguin</span>      <span class="mi">2</span>
<span class="n">dtype</span><span class="p">:</span> <span class="n">UInt8</span>
</pre></div>


<p>Note that <code>UInt8</code> represents the pandas type with the mask, and <code>uint8</code> (lowercase) represents the
original type based on numpy. Also note that the new type may not be as stable as the old, and may not
implement all the operations.</p>
<p>While the new data type fixes this specific problem, the fact that pandas silently casts a data type
when needed is very convenient for the use cases of data analysts, but in my opinion does a poor job
to the interests of precision and reliability of data engineers. And while the <code>.loc[]</code> syntax is very
convenient, doesn't allow us to solve the problem with a simple parameter. A new
<a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html">pandas option</a> could be an option
to control whether we want pandas to automatically cast columns when needed, or raise an exception instead.
But as far as I know, there has not been discussion about it.</p>
<h2>The most popular pandas function</h2>
<p>CSV is in general a poor format to store data. It has a clear advantage, that is being able
to open CSV files in a text editor. Other than that, I think all are disadvantages:</p>
<ul>
<li>Inefficient storage (space that file uses in disk)</li>
<li>Inefficient I/O (because the volume of data, and also the required casting)</li>
<li>Lack of types (everything is a string in a CSV, so original types are lost)</li>
<li>Lack of a standard (different quoting, delimiters,...)</li>
</ul>
<p>Despite of those, CSV happens to be one of the most popular formats out there, being the
page <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html">pandas.read_csv</a>
the one with most visits in the pandas documentation.</p>
<p>To manage all the trickiness of the format, <code>pandas.read_csv</code> provides as much as 50
arguments, to customize for your file format, and for your needs.
<a href="https://github.com/InvestmentSystems/static-frame">StaticFrame</a> a project (somehow)
aiming to compete with pandas, contains the next sentence in its README file:</p>
<blockquote>
<p>The Pandas CSV reader far out-performs the NumPy-based reader in StaticFrame: thus, for now, using Frame.from_pandas(pd.read_csv(fp)) is recommended for loading CSV files.</p>
</blockquote>
<p>This gives an idea of all the complexity in the CSV parser, not only in terms of the parameters,
but also in terms of how optimized it is for performance.</p>
<p>Despite being one of the most powerful and optimized CSV parsers out there,
<a href="http://twitter.com/dontusethiscode">James Powell</a> gave a
<a href="https://www.youtube.com/watch?v=QkQ5HHEu1b4&amp;t=1554">lightning talk at PyData London 2019</a>
on how the parser could be easily improved in several ways for a use case he's got.</p>
<p>Those include:</p>
<ul>
<li>Assume string columns are properly encoded and load them directly into memory</li>
<li>Optimize date casting by assuming a specific format, and a limited set of values</li>
</ul>
<p>Again, no matter the great job done in implementing pandas, the software is
being unable to fully satisfy all user cases. <code>pandas.read_csv</code> does again a
good job at making life easy to data analysts (as defined at the beginning of this
post). And it also does an impressive job at adding parameters to empower users that
know what they are doing and have production-ready code need (data engineers). But
even with an insane number of parameters like 50, looks like loading a CSV file into
memory may be too complex for a single generic function.</p>
<p>What is the solution here? Personally, I think that having <em>one pandas to rule them all</em>
is still possible and the best option. But not a <code>pandas.read_csv</code> to rule them all.
My view is that pandas shouldn't include I/O modules that are able to load data from
every possible format, and in every possible way. That's just impossible.
But pandas could do a better job at allowing and encouraging an ecosystem of I/O
pandas plugins. I proposed in <a href="https://github.com/pandas-dev/pandas/issues/26804">this issue</a>
a first refactoring that would make this possible. It is still under discussion,
since the proposed changes are big.  I'll write in a different article more details about this proposal.</p>
<h2>Lazy pandas</h2>
<p><img alt="" src="/static/img/blog/two_cultures/lazy_pandas.jpeg"></p>
<p>To conclude this article, I will talk about what in my opinion is one of the biggest
differences between the needs of data analysts using pandas in a Jupyter notebook,
compared to data engineers using it to write production pipelines.</p>
<p>See this example:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="s1">&#39;unicorn&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;spider&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;penguin&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>
<span class="mf">4.0</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span> <span class="o">=</span> <span class="n">num_legs</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span>
         <span class="mi">0</span>
<span class="n">unicorn</span>  <span class="mi">4</span>
<span class="n">spider</span>   <span class="mi">8</span>
<span class="n">penguin</span>  <span class="mi">2</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span> <span class="o">=</span> <span class="n">num_legs</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;legs&#39;</span><span class="p">})</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span>
         <span class="n">legs</span>
<span class="n">unicorn</span>     <span class="mi">4</span>
<span class="n">spider</span>      <span class="mi">8</span>
<span class="n">penguin</span>     <span class="mi">2</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span><span class="p">[</span><span class="s1">&#39;kind&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_legs</span><span class="p">[</span><span class="s1">&#39;legs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;biped&#39;</span><span class="p">,</span>
<span class="o">...</span>                                              <span class="mi">4</span><span class="p">:</span> <span class="s1">&#39;quadruped&#39;</span><span class="p">,</span>
<span class="o">...</span>                                              <span class="mi">8</span><span class="p">:</span> <span class="s1">&#39;octoped&#39;</span><span class="p">})</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span>
         <span class="n">legs</span>       <span class="n">kind</span>
<span class="n">unicorn</span>     <span class="mi">4</span>  <span class="n">quadruped</span>
<span class="n">spider</span>      <span class="mi">8</span>    <span class="n">octoped</span>
<span class="n">penguin</span>     <span class="mi">2</span>      <span class="n">biped</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span> <span class="o">=</span> <span class="n">num_legs</span><span class="p">[</span><span class="n">num_legs</span><span class="o">.</span><span class="n">legs</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">]</span>
         <span class="n">legs</span>       <span class="n">kind</span>
<span class="n">unicorn</span>     <span class="mi">4</span>  <span class="n">quadruped</span>
<span class="n">penguin</span>     <span class="mi">2</span>      <span class="n">biped</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">num_legs</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s1">&#39;num_legs.parquet&#39;</span><span class="p">)</span>
</pre></div>


<p>And compare it with this other code:</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="s1">&#39;unicorn&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;spider&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;penguin&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">})</span>
<span class="o">...</span>        <span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="o">...</span>        <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;legs&#39;</span><span class="p">})</span>
<span class="o">...</span>        <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;legs&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;biped&#39;</span><span class="p">,</span>
<span class="o">...</span>                                                    <span class="mi">4</span><span class="p">:</span> <span class="s1">&#39;quadruped&#39;</span><span class="p">,</span>
<span class="o">...</span>                                                    <span class="mi">8</span><span class="p">:</span> <span class="s1">&#39;octoped&#39;</span><span class="p">}))</span>
<span class="o">...</span>        <span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;legs &lt;= 4&#39;</span><span class="p">)</span>
<span class="o">...</span>        <span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s1">&#39;num_legs.parquet&#39;</span><span class="p">))</span>
</pre></div>


<p>Before you are tempted to think on which one is better, let's discuss which
problem solves each of them.</p>
<p>The first version is part of an iterative process where at every step we need
to visualize how our data looks like. We also may need not only to visualize the
data, but <em>understand</em> or verify it, for example by checking which is the median
of one column. It is likely that at the end of writing that code, we don't care
about it anymore, since we already verified what was in the data, and extracted
the insights we care about.</p>
<p>In the second case, while doing almost the same, the code is written to be read
and to be maintained. If there is a bug in the code, it should be easy to
understand what it does, and fix it. The goal is not to discover anything
while writing the code. But just to add a functionality to a system, and to be
able to run it in a reliable and performant way.</p>
<p>For more information about the style in the second approach, you can check
the must-read <a href="https://tomaugspurger.github.io/method-chaining">Method Chaining</a>
by the pandas maintainer <a href="https://tomaugspurger.github.io/pages/about.html">Tom Augspurger</a>.
Also, I discussed about method chaining in my talk
<a href="https://www.youtube.com/watch?v=hK6o_TDXXN8">Towards pandas 1.0</a>.</p>
<p>Back to the example, pandas let us write code in a way that suits both
data analysts and data engineers. But there is something else that is worth
considering. In the first version, the operations must be executed one at
a time, since they are independent. But in the example using method chaining,
there is no need to execute anything until <code>to_parquet</code> is run. The reason
is that the result is not made available to the user or anywhere else.</p>
<p>This may sound irrelevant at first, since we are going to execute it anyway.
But being able to postpone the actual execution until a later stage, can
be extremely useful in some situations. In the example, if pandas postpones
the execution until it knows all what the user wants to do with all the data,
it could optimize the execution. For example, if the row of the spider is
going to be discarded, why load it to memory and why compute which is its
kind? Some memory and some computation power and time can be saved. In this
toy example it doesn't make a difference, but imagine you want to operate
with 1Tb of data in a file, apply some transformations,
and save the result in another file in disk. With the <em>data analyst approach</em>
this is not feasible when running the code in a normal laptop. And while
pandas is not able to work in an out-of-core way, or optimize the execution
even when using method chaining, that could be implemented.</p>
<p>There are related tools where this lazy execution approach already
exists, mainly <a href="https://dask.org/">Dask</a>. Dask implements a
pandas-like API, where operations are evaluated in a lazy way, and the
final task graph is not only optimized, but distributed over a cluster.
<a href="https://github.com/vaexio/vaex">Vaex</a> is another example of pandas-like
API implemented with lazy evaluation.
<a href="https://youtu.be/2Tt0i823-ec">This talk</a> has a demo showing how Vaex
uses lazy evaluation to deal with data sets with more than one billion
rows.</p>
<p>Lazy evaluation may be out of scope for pandas, and there are many things
that should be changed even before being considered. But in my opinion is
another example on the different needs of the different pandas users.</p>
<p>I guess a dual pandas would be possible, and for the user, may be a
simple pandas option <code>pandas.options.lazy_execution = True</code> would be enough.
Together with few methods to allow users to trigger the execution of a task
graph (e.g. a <code>.collect()</code>).</p>
<p>There are also other approaches that could be considered. With the recent
addition of <a href="https://pandas.pydata.org/pandas-docs/stable/development/extending.html#extension-types">pandas extension arrays</a>,
custom data types can be implemented. And having types for memory
maps, or calculated columns could be an option that could allow
some sort of laziness. In the example, we could have a normal
DataFrame, that could have a kind column that does not actually save
the strings <code>biped</code>, <code>quadruped</code>,... but instead stores the
function applied, and to which column. The actual lookup could then
happen after the data is filtered.</p>
<p>Whatever could be the approach, it would require major changes to
pandas internals, and it's not something that could be implemented
easily. Custom data types can be implemented, but currently some
operations will convert the data to numpy arrays, and would not
allow having a proper lazy data type.</p>
<h2>Conclusion</h2>
<p>I think the number of pandas users, and the different kinds of work
that are being done are evidence of many good design decisions and
implementation. But conflicting interests among groups of users do
exist. In some cases is doable to find a good solution for most
use cases. In others is not obvious and serving better our users would
require a huge amount of work.</p>
<p>Personally, I think a more modular pandas architecture would make it
easier to adjust to every kind of user. By having more than one version
of <code>pandas.read_csv</code> different users could implement solutions that
better suit their needs. Same could apply to other areas.</p>
<p>But probably the most important challenge to get those implemented is
not what is the technical solution, but it's in how pandas is developed.
The project is mostly developed by volunteers, including the maintainers
(the people who review the contributions, discuss in the issues that
users open...). Our roadmap is not determined by the needs
of your company or your industry. In my personal case, my roadmap
is determined by my personal interests on what I want to work on,
and on the kind of things I need or I want to see in pandas myself.
If your company would be more productive with certain pandas features or
developments, you should consider hiring someone to improve pandas
based in your interests. You can contact <a href="https://numfocus.org/">NumFOCUS</a>
who manages the pandas funding, can assist with any question, and
is in direct contact with the pandas maintainers. Besides hiring someone
in your own team, you could also provide funds to develop pandas that
are managed by NumFOCUS. Also feel free to <a href="mailto:garcia.marc@gmail.com">contact me</a>
directly if you want more advice, and are interested in this.</p>
            </section>

            <section class="post-info">
                <div class="post-share">
                    <a class="twitter" href="https://twitter.com/share?text=pandas: The two cultures&amp;url=https://datapythonista.github.io/blog/pandas-the-two-cultures.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://datapythonista.github.io/blog/pandas-the-two-cultures.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=https://datapythonista.github.io/blog/pandas-the-two-cultures.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>

                <aside class="post-tags">
<a href="https://datapythonista.github.io/blog/tag/pandas.html">pandas</a>                </aside>

                <div class="clear"></div>


                </section>

                <script type="text/javascript">
                    var disqus = 'datapythonista';
                    var disqus_shortname = 'datapythonista';
                    var disqus_identifier = '/pandas-the-two-cultures.html';
                    var disqus_url = 'https://datapythonista.github.io/blog/pandas-the-two-cultures.html';
                </script>
                <noscript>Please enable JavaScript to view the comments.</noscript>
                <section class="post-comments">
                        <a id="show-disqus" class="post-comments-activate" data-disqus-identifier="/pandas-the-two-cultures.html" >Show Comments</a>
                    <div id="disqus_thread"></div>
                </section>

                <aside class="post-nav">
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>

    <footer id="footer">
      <div class="inner">
        <section class="credits">


          <span class="credits-theme">Theme <a href="https://github.com/arulrajnet/attila" rel="nofollow">Attila</a></span>
          <span class="credits-software">Published with <a href="https://github.com/getpelican/pelican" rel="nofollow">Pelican</a></span>
        </section>
      </div>
    </footer>
  </section>

  <script type="text/javascript" src="https://datapythonista.github.io/blog/theme/js/script.js"></script>

    <!-- Script specified by the user -->
    <script type="text/javascript"  src="https://datapythonista.github.io/blog/../static/js/blog.js"></script>
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1635939-25"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-1635939-25', { 'anonymize_ip': true });
    </script>
<script type="text/javascript">
    var disqus_shortname = 'datapythonista';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>