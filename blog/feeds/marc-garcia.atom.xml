<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>datapythonista blog - Marc Garcia</title><link href="https://datapythonista.github.io/blog/" rel="alternate"></link><link href="https://datapythonista.github.io/blog/feeds/marc-garcia.atom.xml" rel="self"></link><id>https://datapythonista.github.io/blog/</id><updated>2019-11-17T00:00:00+00:00</updated><subtitle>about me</subtitle><entry><title>New pandas workflow</title><link href="https://datapythonista.github.io/blog/new-pandas-workflow.html" rel="alternate"></link><published>2019-11-17T00:00:00+00:00</published><updated>2019-11-17T00:00:00+00:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2019-11-17:/blog/new-pandas-workflow.html</id><summary type="html">&lt;p&gt;Some exciting news. After some years of organizing &lt;a href="https://python-sprints.github.io/"&gt;sprints&lt;/a&gt;,
and maintaining open source, I've been thinking on a more efficient workflow for projects with
high volume of activity, like &lt;a href="https://pandas.pydata.org/"&gt;pandas&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;An exaggerated example would be that I want to create 1,600 issues in pandas. One for each
docstring of …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some exciting news. After some years of organizing &lt;a href="https://python-sprints.github.io/"&gt;sprints&lt;/a&gt;,
and maintaining open source, I've been thinking on a more efficient workflow for projects with
high volume of activity, like &lt;a href="https://pandas.pydata.org/"&gt;pandas&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;An exaggerated example would be that I want to create 1,600 issues in pandas. One for each
docstring of the project, with the flaws that we are able to automatically detect. As a
side know, most of our validations to detect incorrect things in docstrings based on the
&lt;a href="https://numpydoc.readthedocs.io/en/latest/format.html"&gt;numpydoc standard&lt;/a&gt; are now available
in &lt;code&gt;numpydoc&lt;/code&gt; (in master). You can check the
&lt;a href="https://numpydoc.readthedocs.io/en/latest/validation.html"&gt;documentation&lt;/a&gt; to
see how to use it. And the &lt;a href="https://github.com/numpy/numpydoc/blob/master/numpydoc/validate.py#L35"&gt;source code&lt;/a&gt;
for the list of errors we validate.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/numpydoc_validation.png"&gt;&lt;/p&gt;
&lt;p&gt;Back to the example, &lt;a href="https://developer.github.com/v3/"&gt;GitHub API&lt;/a&gt; and our validations
scripts would make it very easy to create those 1,600 GitHub issues. We could create a
label &lt;code&gt;Docstring errors&lt;/code&gt; to identify them, and ask the community for help to fix
those. The community responded extremely well in the past when we ask them for help.
500 people joined our &lt;a href="https://numfocus.org/blog/worldwide-pandas-sprint"&gt;worldwide documentation sprint&lt;/a&gt;.
So, things seem feasible so far.&lt;/p&gt;
&lt;p&gt;There are just two main problems to make all this work:&lt;/p&gt;
&lt;p&gt;First, there is a small number of maintainers who would have to review, give feedback, and
merge the contributions. 1,600 pull requests is surely too much for a small group
of volunteers. We are surely in a much better position now, than when 500 people
contributed in a single day (it took months to deal with all the pull requests of the sprints).
We are around 12 active maintainers, compared to 4 at that time.
And we've been improving on making our workflow more efficient, with the
CI providing every time better feedback. More accurate, and presented in a better
way, so first time contributors can detect problems in their work without much
intervention from maintainers. &lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;
will be key in making our workflow more efficient for code reviews (things like
contributors receiving automated emails when the CI detects something that needs to
be fixed in their work).&lt;/p&gt;
&lt;p&gt;Second, how could people know which of the 1,600 issues are available, and which
are already in the works by someone else? For small projects, GitHub has an option
&lt;code&gt;Assignees&lt;/code&gt; where members of a scrum team can assign to themselves what they are
working on. But this is not possible for a project the size of pandas, since only members
of the organization are able to self-assign issues. And even if we wanted to add
every possible contributor to the pandas GitHub organization, that would be a huge
amount of work for maintainers.&lt;/p&gt;
&lt;p&gt;The best solution should come from GitHub. Adding an option so project admins can
decide whether they want to allow any GitHub user to self-assign issues in their
projects. I've been discussing this with people at GitHub, and it is something it
may be added. But not immediately.&lt;/p&gt;
&lt;p&gt;The good news is that with the help of &lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;
is now possible to achieve the same, in a slightly trickier way. We just added
to pandas an &lt;a href="https://github.com/pandas-dev/pandas/pull/29648"&gt;action to self-assign issues&lt;/a&gt;.
How it works is by just writing a comment with the keyword &lt;code&gt;take&lt;/code&gt; to an issue.
And few seconds later, the action will assign the issue to the commenter. This
is possible because few months ago GitHub added a feature to let
&lt;a href="https://github.blog/2019-06-25-assign-issues-to-issue-commenters/"&gt;assign issues to issue commenters&lt;/a&gt;.
It is not possible even for maintainers to assign an issue to an arbitrary user.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/github_actions_assign.png"&gt;&lt;/p&gt;
&lt;p&gt;With this simple but powerful change, now a much more efficient workflow should
be possible. The workflow could consist in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;People interested in contributing to pandas start by &lt;a href="https://python-sprints.github.io/pandas/guide/pandas_setup.html"&gt;setting up the environment&lt;/a&gt;
  and learn &lt;a href="https://docs.google.com/presentation/d/1rOSYXZPyMe9KXnbVK_xbJzw_-ijxd6bIxndmvPU6L2o/edit?usp=sharing"&gt;how to make an open source contribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Then they check the list of &lt;a href="https://github.com/pandas-dev/pandas/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22+no%3Aassignee"&gt;unassigned good first issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Once they find one that they want to work on, they write a comment with the keyword &lt;code&gt;take&lt;/code&gt; on it&lt;/li&gt;
&lt;li&gt;The issue will disappear from the list of unassigned issues,
  other people won't waste time checking whether it's available or not&lt;/li&gt;
&lt;li&gt;If the person can't finally move forward (got busy, they are not interested anymore...)
  they can simply unassign themselves from the issue, and it will be in the list again&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This new workflow scales to the 1,600 issues or more. Before, potential contributors had
a list with all issues, assigned and not assigned. They had to check each individually for comments
claiming the issue, deal with ambiguity (do messages like "can I work on this?" mean you're working
on the issue?), and possibly have some discussion, before they could know if someone else is working in the issue.&lt;/p&gt;
&lt;p&gt;One obvious problem is if people self-assigning an issue, discontinuing work on it, but not
unassigning the issue. We will see how this works, but even in the worst case, unassigned
issues will still be easy to find if they exist. For the assigned ones, people can check them,
and know immediately who to ask to know if work is still going on, or progress was made.
And to ask if the original assignee is happy to hand over the issue to the new interested contributor.&lt;/p&gt;
&lt;p&gt;Implementing a bot that unassignes issues automatically after N days of inactivity could
also be an option.&lt;/p&gt;</content><category term="misc"></category><category term="pandas"></category></entry><entry><title>Dataframe summit @ EuroSciPy write up</title><link href="https://datapythonista.github.io/blog/dataframe-summit-at-euroscipy.html" rel="alternate"></link><published>2019-09-11T00:00:00+01:00</published><updated>2019-09-11T00:00:00+01:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2019-09-11:/blog/dataframe-summit-at-euroscipy.html</id><summary type="html">&lt;p&gt;Last week took place in Bilbao, Spain, &lt;a href="https://www.euroscipy.org/2019/"&gt;EuroSciPy 2019&lt;/a&gt;.
This year we introduced the &lt;a href="https://www.euroscipy.org/2019/maintainers.html"&gt;maintainers track&lt;/a&gt;
a room dedicated to discussions among maintainers. The idea is similar to the 
&lt;a href="https://en.wikipedia.org/wiki/Birds_of_a_feather_(computing)"&gt;birds of a feather&lt;/a&gt; or unconference
sessions of other conferences. But focussed on open source maintainers and contributors. And
we scheduled …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last week took place in Bilbao, Spain, &lt;a href="https://www.euroscipy.org/2019/"&gt;EuroSciPy 2019&lt;/a&gt;.
This year we introduced the &lt;a href="https://www.euroscipy.org/2019/maintainers.html"&gt;maintainers track&lt;/a&gt;
a room dedicated to discussions among maintainers. The idea is similar to the 
&lt;a href="https://en.wikipedia.org/wiki/Birds_of_a_feather_(computing)"&gt;birds of a feather&lt;/a&gt; or unconference
sessions of other conferences. But focussed on open source maintainers and contributors. And
we scheduled most of the sessions in advanced, to attract the interested people to join the
conference. We also had a maintainers plenary session, in which 26 maintainers of popular
open source scientific projects participated (my guess is that around 50 maintainers attended
the conference).&lt;/p&gt;
&lt;h2&gt;Dataframe summit session&lt;/h2&gt;
&lt;p&gt;One of the sessions was a 2 hours discussion on Python dataframes. 16 people attended it, around
half of them were maintainers of dataframe open source libraries. There were also pandas users
and contributors, maintainers of other projects (PyPy, pytest) and people interested in being involved.
Also the developer of a proprietary dataframe library in Python, who could also add value to the discussion.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/static/img/blog/dataframe_summit.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;Those were the libraries represented:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/pandas-dev/pandas"&gt;pandas&lt;/a&gt;&lt;/strong&gt; Flexible and powerful data analysis / manipulation library for Python&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/dask/dask"&gt;Dask&lt;/a&gt;&lt;/strong&gt; Parallel computing with task scheduling&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/vaexio/vaex"&gt;Vaex&lt;/a&gt;&lt;/strong&gt; Out-of-Core DataFrames for Python&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/modin-project/modin"&gt;Modin&lt;/a&gt;&lt;/strong&gt; A dataframe framework that scales the pandas API with &lt;a href="https://github.com/ray-project/ray"&gt;Ray&lt;/a&gt; and &lt;a href="https://github.com/dask/dask"&gt;Dask&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/QuantStack/xframe"&gt;xframe&lt;/a&gt;&lt;/strong&gt; DataFrame library in C++&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We started by personal introductions, project introductions, and what people wanted to get out
of the session (many people already proposed topics before the event, and we defined an agenda with those).&lt;/p&gt;
&lt;h3&gt;Document the ecosystem&lt;/h3&gt;
&lt;p&gt;One of the first topics discussed was on how to let users know what is the best dataframe
tool for their job, and how the existing packages are different. The general consensus was
that the &lt;a href="https://pandas.pydata.org/pandas-docs/stable/ecosystem.html"&gt;pandas ecosystem&lt;/a&gt; page
is the best place for it. There are already plans to improve this page (and plans and work in progress to improve
the look and feel of the pandas website and documentation).&lt;/p&gt;
&lt;h3&gt;Apache Arrow&lt;/h3&gt;
&lt;p&gt;Another topic that was discussed early was &lt;strong&gt;&lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt;&lt;/strong&gt;. Arrow's mission is to
provide a common memory representation for all dataframe libraries. So, libraries don't need to reinvent the
wheel, and transferring data among packages (e.g. pandas to R) can be done without transformations or even without
copying the memory.&lt;/p&gt;
&lt;p&gt;Vaex is already using Arrow, and pandas has plans in its &lt;a href="https://pandas.pydata.org/pandas-docs/stable/development/roadmap.html"&gt;roadmap&lt;/a&gt;
to move in that direction. People were in general happy with the idea, but there were some concerns
about decisions made in Arrow (mainly contributed by Sylvain, from xframe):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apache arrow C++ API and implementation not following common C++ idioms&lt;/li&gt;
&lt;li&gt;Using a monorepo (including all bindings in the same repo as Arrow)&lt;/li&gt;
&lt;li&gt;Not a clear distinction between the specification and implementation (as in for instance project Jupyter)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not only related to Arrow, but it was mentioned that would be useful to have
dataframes for streaming data. A library named &lt;a href="https://github.com/finos/perspective"&gt;Perspective&lt;/a&gt;
exists, which implements something similar, and has &lt;a href="https://github.com/timkpaine/perspective-python/"&gt;Python bindings&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Interoperability&lt;/h3&gt;
&lt;p&gt;The next topic was about &lt;strong&gt;interoperability&lt;/strong&gt;. How dataframe libraries can interact among them, and
with the rest of the ecosystem. Examples can be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using the same plotting backends from different dataframe libraries&lt;/li&gt;
&lt;li&gt;Passing to &lt;a href="https://scikit-learn.org/stable/index.html"&gt;scikit-learn&lt;/a&gt; pandas-like dataframe objects&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There was consensus that defining a standard (and minimal) dataframe API would help. Dataframe libraries
could extend this smaller API and offer users a much bigger APIs (like pandas). But having a subset of
operations and methods would be very useful for third party libraries expecting dataframe objects.&lt;/p&gt;
&lt;p&gt;Devin from Modin is doing research at UC Berkeley on defining this API, and he's already got some
documentation he's happy to share. Modin is already implemented with this design, and while it's
one of the less mature participating projects (in Devin's words), it's user-facing layer could
potentially be reused by other projects reimplementing dataframes with a different backend. Devin
has shared the documentation for this &lt;a href="https://modin.readthedocs.io/en/latest/architecture.html#system-architecture"&gt;design&lt;/a&gt; and the &lt;a href="https://modin.readthedocs.io/en/latest/architecture.html#modin-dataframe-api"&gt;corresponding API&lt;/a&gt; on
the &lt;a href="https://modin.readthedocs.io"&gt;Modin documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It was noted that could be useful to have a common test suite, if a standard dataframe API is defined.
There was agreement that the pandas test suite is not appropriate for other packages.&lt;/p&gt;
&lt;p&gt;NumPy did something similar in &lt;a href="https://numpy.org/neps/nep-0018-array-function-protocol.html"&gt;NEP-18&lt;/a&gt;,
which can be used as reference.&lt;/p&gt;
&lt;h3&gt;Public API improvements&lt;/h3&gt;
&lt;p&gt;At the end of the session, we discussed about possible improvements to the public pandas API.
Since several of the participants reimplemented the pandas API, was a good opportunity to see
places where they found inconsistencies, or where the API was making their lives difficult
when using other approaches.&lt;/p&gt;
&lt;p&gt;Indexing was the part of pandas that other maintainers were less happy about. The way &lt;code&gt;.loc&lt;/code&gt;
behaves was one of the comments. And being forced to have a default index, and not being able
to index by other columns were other comments.&lt;/p&gt;
&lt;h3&gt;Next steps&lt;/h3&gt;
&lt;p&gt;Couple of things were discussed to keep those discussions active, and keep coordinating on
shaping the dataframes of the future.&lt;/p&gt;
&lt;p&gt;The first was to start a workgroup, or a distribution list (or discourse). The &lt;code&gt;pandas-dev&lt;/code&gt;
list wasn't used by the participants (except the pandas maintainers), and it didn't seem
to be the appropriate place.&lt;/p&gt;
&lt;p&gt;Another idea would be to organize another bigger dataframe summit in the future. It was
proposed to be hosted somewhere in the Caribbean (ok, it was me who proposed that, and
everybody else laughed, but here I leave it again). :)&lt;/p&gt;</content><category term="misc"></category><category term="pandas"></category></entry><entry><title>Setting up Fedora</title><link href="https://datapythonista.github.io/blog/setting-up-fedora.html" rel="alternate"></link><published>2018-12-05T00:00:00+00:00</published><updated>2018-12-05T00:00:00+00:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2018-12-05:/blog/setting-up-fedora.html</id><summary type="html">&lt;p&gt;Today I've got my new Dell XPS (with Ubuntu preinstalled), and this is the procedure
to set it up, and get my perfect working environment. This is expected to be useful
mainly for my &lt;strong&gt;future self&lt;/strong&gt;, but sharing it here in case someone else can find
ideas or tips that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I've got my new Dell XPS (with Ubuntu preinstalled), and this is the procedure
to set it up, and get my perfect working environment. This is expected to be useful
mainly for my &lt;strong&gt;future self&lt;/strong&gt;, but sharing it here in case someone else can find
ideas or tips that are useful. Also happy to receive comments on how you do things
differently (and potentially better).&lt;/p&gt;
&lt;p&gt;My operating system of choice is &lt;a class="reference external" href="https://spins.fedoraproject.org/mate-compiz/"&gt;Fedora MATE Compiz&lt;/a&gt;,
I think GNOME 3 was a big mistake, so staying in what was GNOME 2.&lt;/p&gt;
&lt;p&gt;After downloading the ISO, I create the live USB with &lt;a class="reference external" href="https://unetbootin.github.io/"&gt;UNetbootin&lt;/a&gt;.
This works well, but it has a problem. The label of the volume is not updated, and it becomes inconsistent
with the one that GRUB loads. This will create a lot of warnings like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
dracut-initqueue[602]: Warning dracut-initqueue timeout - starting timeout scripts
&lt;/pre&gt;
&lt;p&gt;With couple of final warnings:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Warning: /dev/disk/by-label/Fedora-Live-WS-x86_64-29-1 does not exist
Warning: /dev/mapper/live-rw does not exist
&lt;/pre&gt;
&lt;p&gt;To fix it, we just need to know the label of our live USB (can be obtained in the rescue terminal by
calling &lt;tt class="docutils literal"&gt;blkid&lt;/tt&gt;). And then, in the GRUB menu, press &lt;cite&gt;e&lt;/cite&gt; with the &lt;cite&gt;Start Fedora Live&lt;/cite&gt; option
selected, and replace the value of &lt;cite&gt;LABEL&lt;/cite&gt; by the correct one. A &lt;cite&gt;Ctrl-x&lt;/cite&gt; will make the system
boot with the updated configuration, and should start normally. This
&lt;a class="reference external" href="https://www.youtube.com/watch?v=C3iSqmfPRxY"&gt;video&lt;/a&gt; shows the process step by step.&lt;/p&gt;
&lt;p&gt;The default configurations during the installation work well for me (using 50Gb for &lt;cite&gt;/&lt;/cite&gt;, the rest
for &lt;cite&gt;/home/&lt;/cite&gt;, and &lt;cite&gt;ext4&lt;/cite&gt; filesystem). But I encrypt &lt;cite&gt;/home/&lt;/cite&gt;, which is not enabled by default.&lt;/p&gt;
&lt;p&gt;Once the new system is installed, and running, those are the tasks I perform.&lt;/p&gt;
&lt;div class="section" id="configuration"&gt;
&lt;h2&gt;Configuration&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p class="first"&gt;Merge both panels into one, and leave it to the bottom (removing the workspaces and Thunderbird,
which I not use)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Mouse setup: enable touchpad click, natural scrolling and increase acceleration&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Disable screensaver, and make windows be selected when mouse moves over them&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Change the terminal shorcuts to change and move tabs (I got used to the KDE shortcuts and never
bothered in learning the GNOME ones)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Change the default search engine in Firefox to &lt;a class="reference external" href="https://duckduckgo.com/"&gt;DuckDuckGo&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Set up couple of aliases in &lt;cite&gt;~/.bashrc&lt;/cite&gt;: &lt;tt class="docutils literal"&gt;alias &lt;span class="pre"&gt;rgrep=&amp;quot;grep&lt;/span&gt; &lt;span class="pre"&gt;-R&amp;quot;&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;alias &lt;span class="pre"&gt;vi=&amp;quot;vim&amp;quot;&lt;/span&gt;&lt;/tt&gt; (which
doesn't seem to be required anymore)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Set up &lt;cite&gt;vim&lt;/cite&gt; for Python (and remove some unwanted features like folding):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
syntax on
set number
set autoindent
set expandtab
set shiftwidth=4
set tabstop=4
set nofoldenable

execute pathogen#infect()
set statusline+=%#warningmsg#
set statusline+=%{SyntasticStatuslineFlag()}
set statusline+=%*
let g:syntastic_always_populate_loc_list = 1
let g:syntastic_auto_loc_list = 0
let g:syntastic_check_on_open = 1
let g:syntastic_check_on_wq = 0
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="installing-software"&gt;
&lt;h2&gt;Installing software&lt;/h2&gt;
&lt;p&gt;Quite happy with the software that comes preinstalled with Fedora, but few things left to install.
First adding &lt;a class="reference external" href="https://rpmfusion.org"&gt;RPM Fusion&lt;/a&gt; repositories:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo dnf install https://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm https://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm
&lt;/pre&gt;
&lt;p&gt;Then updating the system:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo dnf update
&lt;/pre&gt;
&lt;p&gt;Then installing the development group:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo dnf groupinstall &amp;quot;Development Tools&amp;quot;
&lt;/pre&gt;
&lt;p&gt;Also installing all the missing packages (or not missing, but had this list for some years now):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo dnf install vim-enhanced git vlc gimp inkscape unzip
&lt;/pre&gt;
&lt;p&gt;And finally installing &lt;a class="reference external" href="https://conda.io/miniconda.html"&gt;Miniconda&lt;/a&gt;. I prefer Miniconda over
Anaconda, because I don't like to have any package in the base environment. So, in every
environment I'm sure there are the packages I'm using (and it's not falling back to the base
environment version, which can be different of the expected).&lt;/p&gt;
&lt;/div&gt;
</content><category term="misc"></category></entry><entry><title>Useful git commands</title><link href="https://datapythonista.github.io/blog/useful-git-commands.html" rel="alternate"></link><published>2018-11-08T00:00:00+00:00</published><updated>2018-11-08T00:00:00+00:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2018-11-08:/blog/useful-git-commands.html</id><summary type="html">&lt;p&gt;While &lt;cite&gt;git&lt;/cite&gt; is surely one of my favorite tools, and increases my productivity
in a sometimes unbelivable way (like when working on 3 or 5 features at the
same time), some times there are operations that can be a bit tricky.&lt;/p&gt;
&lt;p&gt;There are plenty of git tutorials and guides to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;While &lt;cite&gt;git&lt;/cite&gt; is surely one of my favorite tools, and increases my productivity
in a sometimes unbelivable way (like when working on 3 or 5 features at the
same time), some times there are operations that can be a bit tricky.&lt;/p&gt;
&lt;p&gt;There are plenty of git tutorials and guides to get started and that explain
the basic concepts. This post is not one of them. If that is what you need,
you can check these great resources:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://rogerdudler.github.io/git-guide/"&gt;git - the simple guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://medium.com/girl-writes-code/git-is-a-directed-acyclic-graph-and-what-the-heck-does-that-mean-b6c8dec65059"&gt;Git is a Directed Acyclic Graph and What the Heck Does That Mean?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://think-like-a-git.net/"&gt;Think Like (a) Git&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://git-scm.com/doc"&gt;Official documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is another quite popular resource, that doesn't focus on explaining
the concepts, but on what to do if you get into certain cases (aka problems):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://ohshitgit.com/"&gt;Oh shit,git!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More on the style of the latter, in this post I'll explain some operations
that are somehow advanced, I don't think are well known, but I use them
frequently. So, hopefully they can be useful to others.&lt;/p&gt;
&lt;div class="section" id="i-ve-got-some-cool-changes-but-my-history-is-a-mess"&gt;
&lt;h2&gt;I've got some cool changes, but my history is a mess&lt;/h2&gt;
&lt;p&gt;There are many reasons why this can happen. The one that I encounter most
frequently is people opening a pull request, that does not only contain
the user changes (and possibly some merges from master), but instead it
contains commits from other users in the branch, as if they were part of
the pull request. I never spent the time to research what is the cause, but
this is what I usually recommend or do.&lt;/p&gt;
&lt;p&gt;Whether it is the previous case, or because of any other reason, if you have
some changes in your branch mixed with a messy git history, the easiest
way I know to go back to a state under control is:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git fetch upstream&lt;/tt&gt;: Just updating our local repository.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git merge upstream/master&lt;/tt&gt;: Getting anything in the latest repository
version into our branch.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git reset &lt;span class="pre"&gt;--soft&lt;/span&gt; upstream/master&lt;/tt&gt;: This will make that the git history
in our branch is exactly as the one in master, replacing our messy history.
And it will leave in our staging area all the changes that we made, compared
to master.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git commit &lt;span class="pre"&gt;-m&lt;/span&gt; &amp;quot;All my changes in a single commit&amp;quot;&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now the history in our branch will be equivalent as if we just created
the branch from the latest version, and added a single commit with all our
changes. As usual, we shouldn't rewrite the history if someone else pulled
our commits. But if this is a local branch, or it is remote but only used
to open a pull request, that should be all right.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="i-have-changes-in-the-working-directory-and-i-want-to-change-branch"&gt;
&lt;h2&gt;I have changes in the working directory, and I want to change branch&lt;/h2&gt;
&lt;p&gt;There are also different cases for this. The simplest case (but not
common in my case) is that you are working in a branch, and want to
go to make some changes to a different one, but your current changes are
not in a state that you want to commit.&lt;/p&gt;
&lt;p&gt;The other cases (the ones that happen to me in practice) are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;You start working in some changes, and you realize that you are in the
wrong branch.&lt;/li&gt;
&lt;li&gt;You are making some last minute addition to a pull request, and before
you commit and push, the pull request is merged. So, you want to continue
the work in a new branch.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The problem is that when you have uncommitted changes in your working
directory, and you try to change branch, you get the next error message:
&lt;cite&gt;error: Your local changes to the following files would be overwritten by
checkout&lt;/cite&gt; preventing any branch change until you commit those changes.
But committing in the current branch is not what we want.&lt;/p&gt;
&lt;p&gt;The solution in this case is &lt;tt class="docutils literal"&gt;git stash&lt;/tt&gt;. With it, the changes in the
working directory are saved into a stack, and the working directory becomes
clean.  This allows us to freely switch branches, and perform other operations.
Once we have the environment ready, and we are in the branch in which the
stacked changes belong to, then we can simply &lt;tt class="docutils literal"&gt;git stash apply&lt;/tt&gt;. We will get
the uncommitted changes back to the working directory.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="i-want-to-test-or-edit-someone-else-pull-request"&gt;
&lt;h2&gt;I want to test or edit someone else pull request&lt;/h2&gt;
&lt;p&gt;This is something that mainly project maintainers do, but that can be useful
for anyone. In general, when someone opens a pull request, the changes are
reviewed, and feedback is provided, both in the GitHub (or similar)
interface. And the author, who already got the branch locally, makes changes
and run the code. But in some cases, it may be useful to get the changes of the
pull request locally, so they can be run, and edited.&lt;/p&gt;
&lt;p&gt;One example could be a stale pull request, that was opened many months ago
and that the author is not interesting in updating anymore. But it contains
code, that with few changes, would be nice to get merged.&lt;/p&gt;
&lt;p&gt;Git is a distributed system, and there is nothing in git itself that tells
which is the &amp;quot;official&amp;quot; repository, and which are forks. To interact
with other repositories from your local copy, all you need is to set a
remote, fetch the changes, and switch to their branches. This would be
done with the commands:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git remote add &lt;span class="pre"&gt;&amp;lt;remote-name-for-user-fork&amp;gt;&lt;/span&gt; &lt;span class="pre"&gt;&amp;lt;url-to-user-fork&amp;gt;&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git fetch &lt;span class="pre"&gt;&amp;lt;remote-name-for-user-fork&amp;gt;&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, we already have locally all the data in the repo of the author of the
pull request. Next thing is to checkout the branch used for the pull request.
This can be done with:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git branch &lt;span class="pre"&gt;&amp;lt;branch-name&amp;gt;&lt;/span&gt; &lt;span class="pre"&gt;--track&lt;/span&gt; &lt;span class="pre"&gt;&amp;lt;remote-name-for-user-fork&amp;gt;/&amp;lt;branch-name&amp;gt;&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now we have the code in the pull request in our working directory. And we can
run or edit.&lt;/p&gt;
&lt;p&gt;GitHub has an option when creating a pull request &amp;quot;Allow edits from
maintainers&amp;quot;, that is checked by default. If the author of the pull request
left it checked, then maintainers can push to the pull request branch
after editing it locally. So, the updates are made in the same pull request,
which can be merged when it's ready.&lt;/p&gt;
&lt;p&gt;For people that are not maintainers, when the checkbox was unchecked, or when
the fork of the author does not exist anymore, pushing to &lt;cite&gt;origin&lt;/cite&gt; (your own
fork), and opening a new pull request is required.&lt;/p&gt;
&lt;p&gt;If editing other people branches is something that needs to be done often, it
is probably a good idea to use &lt;cite&gt;hub&lt;/cite&gt;, a tool from GitHub. It can be installed
with conda:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;conda install &lt;span class="pre"&gt;-c&lt;/span&gt; &lt;span class="pre"&gt;conda-forge&lt;/span&gt; hub&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And then, checking out the branch from a pull request is as simple as:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;hub checkout &lt;span class="pre"&gt;&amp;lt;github-url-of-the-pull-request&amp;gt;&lt;/span&gt;&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Which will set up the remotes, and make the branch track the parent, so
changes can be pushed with a simple &lt;tt class="docutils literal"&gt;git push&lt;/tt&gt; given the right permissions.&lt;/p&gt;
&lt;/div&gt;
</content><category term="misc"></category></entry><entry><title>Blog moved</title><link href="https://datapythonista.github.io/blog/blog-moved.html" rel="alternate"></link><published>2018-09-08T00:00:00+01:00</published><updated>2018-09-08T00:00:00+01:00</updated><author><name>Marc Garcia</name></author><id>tag:datapythonista.github.io,2018-09-08:/blog/blog-moved.html</id><summary type="html">&lt;p&gt;It's been a while since I wanted to move my blog out of blogger.&lt;/p&gt;
&lt;p&gt;Today I finally did it. :)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hello world (from Pelican)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This new blog uses Pelican, and is hosted on GitHub pages. Which will
let me create blog posts by simply using restructuredText, or
Jupyter notebooks.&lt;/p&gt;
&lt;p&gt;You …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It's been a while since I wanted to move my blog out of blogger.&lt;/p&gt;
&lt;p&gt;Today I finally did it. :)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;hello world (from Pelican)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This new blog uses Pelican, and is hosted on GitHub pages. Which will
let me create blog posts by simply using restructuredText, or
Jupyter notebooks.&lt;/p&gt;
&lt;p&gt;You can check the source code here: &lt;a class="reference external" href="https://github.com/datapythonista/datapythonista.github.io"&gt;https://github.com/datapythonista/datapythonista.github.io&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More info: &lt;a class="reference external" href="https://blog.getpelican.com/"&gt;https://blog.getpelican.com/&lt;/a&gt;&lt;/p&gt;
</content><category term="misc"></category></entry></feed>